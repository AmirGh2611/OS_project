{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## libraries"
      ],
      "metadata": {
        "id": "Nu7IL5b5m7Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch import optim"
      ],
      "metadata": {
        "id": "SceLLwdcm-KG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reading data"
      ],
      "metadata": {
        "id": "nug2GASlnIgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train = MNIST(root='./data', train=True, transform=t, download=True)\n",
        "test = MNIST(root='./data', train=False, transform=t, download=True)\n",
        "\n",
        "x_train, y_train = train.data, train.targets\n",
        "x_test, y_test = test.data, test.targets"
      ],
      "metadata": {
        "id": "vOxGVrgXnLdM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocessing"
      ],
      "metadata": {
        "id": "LgC-8PqinPvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(x, y):\n",
        "    x = x.type(torch.float32)\n",
        "    x = (x - x.mean()) / x.std()\n",
        "    x = x.unsqueeze(1)\n",
        "    return x, y\n",
        "x_train, y_train = preprocessing(x_train, y_train)\n",
        "x_test, y_test = preprocessing(x_test, y_test)"
      ],
      "metadata": {
        "id": "zu8JUEB1njuU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataloader"
      ],
      "metadata": {
        "id": "ArDokMtGnwwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = TensorDataset(x_train, y_train)\n",
        "train_set, valid_set = random_split(train_set, [50000, 10000])\n",
        "\n",
        "test_set = TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=1024, shuffle=False)"
      ],
      "metadata": {
        "id": "ezBm5Bkunsrr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "sW8Eb1rBn4PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool2d((14, 14))\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((7, 7))\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((7, 7))\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=256 * 7 * 7, out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Linear(in_features=256, out_features=128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Linear(in_features=128, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "i3UX68dRn55F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper parameters"
      ],
      "metadata": {
        "id": "Kw9LlqRroQC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ConvNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "epoch = 30\n",
        "loss_thresh = 1"
      ],
      "metadata": {
        "id": "FKlDBqVPoYvD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "mbEsjQkloaIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(epoch):\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = loss_fn(output, label)\n",
        "        if loss.item() < loss_thresh:\n",
        "            torch.save(model, 'model.ckpt')\n",
        "            loss_thresh = loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f\"epoch: {epoch}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJ37oN4obBC",
        "outputId": "93851850-3525-4683-a239-711dfa07274f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 2.305349826812744\n",
            "epoch: 0, loss: 0.0597643107175827\n",
            "epoch: 1, loss: 0.04330001398921013\n",
            "epoch: 1, loss: 0.07739507406949997\n",
            "epoch: 2, loss: 0.026307400315999985\n",
            "epoch: 2, loss: 0.0780431479215622\n",
            "epoch: 3, loss: 0.03432378172874451\n",
            "epoch: 3, loss: 0.03570227697491646\n",
            "epoch: 4, loss: 0.016359742730855942\n",
            "epoch: 4, loss: 0.03945133462548256\n",
            "epoch: 5, loss: 0.0169031023979187\n",
            "epoch: 5, loss: 0.020414823666214943\n",
            "epoch: 6, loss: 0.007927187718451023\n",
            "epoch: 6, loss: 0.013646220788359642\n",
            "epoch: 7, loss: 0.01542949303984642\n",
            "epoch: 7, loss: 0.07200226187705994\n",
            "epoch: 8, loss: 0.05090324580669403\n",
            "epoch: 8, loss: 0.018404094502329826\n",
            "epoch: 9, loss: 0.002031586365774274\n",
            "epoch: 9, loss: 0.03749333322048187\n",
            "epoch: 10, loss: 0.037784479558467865\n",
            "epoch: 10, loss: 0.021196449175477028\n",
            "epoch: 11, loss: 0.017011458054184914\n",
            "epoch: 11, loss: 0.0007282367441803217\n",
            "epoch: 12, loss: 0.01117569487541914\n",
            "epoch: 12, loss: 0.006575259380042553\n",
            "epoch: 13, loss: 0.016123831272125244\n",
            "epoch: 13, loss: 0.01425870694220066\n",
            "epoch: 14, loss: 0.005424903705716133\n",
            "epoch: 14, loss: 0.010888593271374702\n",
            "epoch: 15, loss: 0.0018553115660324693\n",
            "epoch: 15, loss: 0.005632088519632816\n",
            "epoch: 16, loss: 0.01691398024559021\n",
            "epoch: 16, loss: 0.005676682107150555\n",
            "epoch: 17, loss: 0.00806101132184267\n",
            "epoch: 17, loss: 0.005511341616511345\n",
            "epoch: 18, loss: 0.002357698045670986\n",
            "epoch: 18, loss: 0.006068281829357147\n",
            "epoch: 19, loss: 0.004649658687412739\n",
            "epoch: 19, loss: 0.0010827556252479553\n",
            "epoch: 20, loss: 0.012004870921373367\n",
            "epoch: 20, loss: 0.024743784219026566\n",
            "epoch: 21, loss: 0.0036583621986210346\n",
            "epoch: 21, loss: 0.008387967944145203\n",
            "epoch: 22, loss: 0.0022610321175307035\n",
            "epoch: 22, loss: 0.026117468252778053\n",
            "epoch: 23, loss: 0.0002694085123948753\n",
            "epoch: 23, loss: 0.009046194143593311\n",
            "epoch: 24, loss: 0.00409341836348176\n",
            "epoch: 24, loss: 0.00022362108575180173\n",
            "epoch: 25, loss: 0.005337072536349297\n",
            "epoch: 25, loss: 0.03253832086920738\n",
            "epoch: 26, loss: 0.0712902769446373\n",
            "epoch: 26, loss: 0.014445112086832523\n",
            "epoch: 27, loss: 0.011267335154116154\n",
            "epoch: 27, loss: 0.005493397358804941\n",
            "epoch: 28, loss: 9.891774243442342e-05\n",
            "epoch: 28, loss: 0.0002367321285419166\n",
            "epoch: 29, loss: 0.0004275915853213519\n",
            "epoch: 29, loss: 0.0016979853389784694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## validation"
      ],
      "metadata": {
        "id": "iF1wmgkYoidr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (image, label) in enumerate(valid_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(image)\n",
        "        loss = loss_fn(output, label)\n",
        "        if i % 10 == 0:\n",
        "            print(f\"loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMYj7T5folZl",
        "outputId": "57f7073b-6cac-4045-ec07-039cdc802f77"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.03072669357061386\n",
            "loss: 0.09085695445537567\n",
            "loss: 0.04872990399599075\n",
            "loss: 0.0049851397052407265\n"
          ]
        }
      ]
    }
  ]
}